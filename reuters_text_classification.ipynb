{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification for reuters21578"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I am describing development of a naive text classification system for reuters21578.\n",
    "\n",
    "As mentioned in the task description, the task of text classification on reuters21578 requires quite a few choice while developing. Let's look at different topics and corresponding news counts which shown as `USABLE` i.e. `TRAIN + TEST`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Set</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>earn</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acq</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>2369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>money-fx</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>grain</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>crude</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>trade</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>interest</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>ship</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>wheat</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>corn</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>dlr</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>money-supply</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>oilseed</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>sugar</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>coffee</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>gnp</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>gold</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>veg-oil</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>soybean</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>nat-gas</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bop</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>livestock</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>cpi</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>reserves</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>cocoa</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>carcass</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>jobs</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>copper</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>yen</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>rice</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>cruzado</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>f-cattle</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>lin-meal</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>peseta</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>dkr</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>citruspulp</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>sfr</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>rupiah</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>ringgit</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>cottonseed</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>red-bean</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>rape-meal</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>corn-oil</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>tung-oil</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>ffr</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>tung</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>austral</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>drachma</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>escudo</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bfr</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>flaxseed</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>castor-meal</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>groundnut-meal</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>silk</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>lupin</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>mexpeso</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>cotton-meal</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>hk</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>palm-meal</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>singdlr</td>\n",
       "      <td>USABLE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Topic     Set  Count\n",
       "143            earn  USABLE   3965\n",
       "3               acq  USABLE   2369\n",
       "295        money-fx  USABLE    719\n",
       "183           grain  USABLE    583\n",
       "115           crude  USABLE    580\n",
       "507           trade  USABLE    487\n",
       "223        interest  USABLE    480\n",
       "435            ship  USABLE    287\n",
       "523           wheat  USABLE    283\n",
       "79             corn  USABLE    239\n",
       "131             dlr  USABLE    175\n",
       "299    money-supply  USABLE    174\n",
       "327         oilseed  USABLE    171\n",
       "479           sugar  USABLE    162\n",
       "67           coffee  USABLE    139\n",
       "175             gnp  USABLE    136\n",
       "179            gold  USABLE    124\n",
       "519         veg-oil  USABLE    124\n",
       "467         soybean  USABLE    111\n",
       "307         nat-gas  USABLE    105\n",
       "27              bop  USABLE    105\n",
       "275       livestock  USABLE     99\n",
       "107             cpi  USABLE     97\n",
       "399        reserves  USABLE     73\n",
       "55            cocoa  USABLE     73\n",
       "35          carcass  USABLE     68\n",
       "243            jobs  USABLE     67\n",
       "71           copper  USABLE     65\n",
       "535             yen  USABLE     59\n",
       "407            rice  USABLE     59\n",
       "..              ...     ...    ...\n",
       "119         cruzado  USABLE      1\n",
       "151        f-cattle  USABLE      1\n",
       "259        lin-meal  USABLE      1\n",
       "351          peseta  USABLE      1\n",
       "127             dkr  USABLE      1\n",
       "51       citruspulp  USABLE      1\n",
       "431             sfr  USABLE      1\n",
       "419          rupiah  USABLE      1\n",
       "411         ringgit  USABLE      1\n",
       "103      cottonseed  USABLE      1\n",
       "395        red-bean  USABLE      1\n",
       "383       rape-meal  USABLE      1\n",
       "83         corn-oil  USABLE      1\n",
       "515        tung-oil  USABLE      0\n",
       "155             ffr  USABLE      0\n",
       "511            tung  USABLE      0\n",
       "15          austral  USABLE      0\n",
       "139         drachma  USABLE      0\n",
       "147          escudo  USABLE      0\n",
       "23              bfr  USABLE      0\n",
       "163        flaxseed  USABLE      0\n",
       "39      castor-meal  USABLE      0\n",
       "191  groundnut-meal  USABLE      0\n",
       "439            silk  USABLE      0\n",
       "283           lupin  USABLE      0\n",
       "291         mexpeso  USABLE      0\n",
       "95      cotton-meal  USABLE      0\n",
       "203              hk  USABLE      0\n",
       "339       palm-meal  USABLE      0\n",
       "447         singdlr  USABLE      0\n",
       "\n",
       "[135 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from reuters21578 import Reuters\n",
    "\n",
    "dataset = Reuters()\n",
    "article_stats = dataset.get_news_stats(mode='offline')\n",
    "display(article_stats[article_stats.Set =='USABLE'].sort_values(by='Count', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As you see there are a few topics that have more than 100 usable news articles. We use the top 10 topics as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "selected_topics_stats = article_stats[article_stats.Set =='USABLE'].sort_values(by='Count', ascending=False).head(10)\n",
    "display(selected_topics_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The next step is to define feature extraction and classification method. We have quite a few choices here! State-of-the-art text classification systems are mostly DL-based. Considering the time limit for this particulare task and limited number of news articles, I decided to use SVM classifier on top of TF-IDF features. I am using NLTK and sklearn for TF-IDF extraction and classification respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "def show_result_table(scores):\n",
    "    tbl = DataFrame(columns=['Topic', 'Precision', 'Recall'])\n",
    "    for topic in scores:\n",
    "        tbl = tbl.append({'Topic': topic,'Precision': scores[topic][0],'Recall': scores[topic][1]}, ignore_index=True)\n",
    "        \n",
    "    display(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfidf_classifier import TFIDFClassifier\n",
    "from reuters21578 import Reuters\n",
    "\n",
    "\n",
    "selected_topics = [item[0] for item in selected_topics_stats.values.tolist()]\n",
    "data_set = Reuters()\n",
    "data_set.load_data()\n",
    "tfidf_classifier = TFIDFClassifier(data_set.get_all_train())\n",
    "print(\"Calculating and adding TFIDF...\")\n",
    "data_set.add_tfidf(tfidf_classifier)\n",
    "\n",
    "scores = dict()\n",
    "for topic in selected_topics:\n",
    "    print(\"Training classifier for :  '{}'\".format(topic))\n",
    "    X_train, Y_train = data_set.get_data(topic, 'TRAIN')\n",
    "    X_test, Y_test = data_set.get_data(topic, 'TEST')\n",
    "    tfidf_classifier.train(X_train, Y_train)\n",
    "    print(\"Testing '{}'\".format(topic))\n",
    "    scores[topic]= tfidf_classifier.get_precision_recall(X_test, Y_test)\n",
    "\n",
    "show_result_table(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see result degrades for topic with lower number of news article. There are many potential ways of exploring different feature extraction and classifications as researchers are suggesting for this task. I did not have enough time to go through published works on this task.\n",
    "For such a task, I would normally go though the data to figure out distribution of words and kind of data filtering that would help better result before trying to play wih classifiers.\n",
    "\n",
    "I would like to mention following points about this implementation \n",
    "- It is not a good practice to upload data on github along with the code. However, there is an encoding problem with file reut2-017.sgm that should be fixed before being used here. Please use the Reuters data provided along with the code. \n",
    "- This implementation assumes that all the data could be held in memory which is possible for such small data set\n",
    "- dataframe operation could be much more efficient and nicer with joint. I had an error with joint that I couldn't fix fast so I sent this implementation\n",
    "\n",
    "In General, test classification tasks are very depending on the amount of data. AS result shows, recall is not consistent even for the top 10 topics. Here are some simple variations that would be nice to try\n",
    "\n",
    "- concatenating uni-gram and bi-gram TFIDF in feature vector. I expect most of the bi-gram TFIDF should be filtered out\n",
    "- It is easier to capture higher order n-gram sequences with correct length and number of filters. CNN with small filter length (e.g. [1,2]) could be useful for top 10 topics with highest number of articles. See <a href=\"http://localhost:8889/notebooks/cnn-based-topic-classification.ipynb\"> CNN-based implementation </a>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
